# 日志收集项目

## 1.Context

### 1.1 make 和 new 的区别

- 共同点：都是用来初始化内存
- 不同点：
  - new 多用来为基本数据类型初始化内存（bool、string、int...），返回的是指针
  - make 用来初始化 slice map channel，返回的是对应类型

### 1.2 两个根函数

- context.Background
- context.TODO

### 1.3 四个with函数

- context.WithCancel：调用了cancel 就会给ctx.Done() 发送信号
- context.WithDeadline：超时了也要调用 cancel()
- context.WithTimeOut：超时了也要调用 cancel()
- context.WithValue：注意 key 需要自定义类型

### 1.4 使用 Context 的注意事项

- 不要把 Context 放在结构体中，要以参数的方式显示传递
- 以 Context 作为参数的函数方法，应该把 Context 放在第一个参数
- 给一个函数方法传递 Context 的时候，不要传递 nil，如果不知道传递什么，就是用 Context.TODO
- Context 的 Value 相关方法应该传递请求与的必要数据，不应该用于传递可选参数
- Context 是线程安全的，可以放心在多个 goroutine 中传递

## 2.日志收集

### 2.1 项目背景

每个业务系统都有日志，当系统出现问题时，需要通过日志信息定位和解决问题。当系统机器比较少时，登陆到服务器上查看即可满足，当系统机器规模巨大，登录到机器上查几乎不现实（分布式的系统，一个系统部署到十几台机器上）。

### 2.2 解决办法

把机器上的日志实时收集，统一的存储到中心系统。再对这些日志建立索引，通过索引即可快速找到对应的日志记录，通过提供一个界面友好的web页面实现日志检索与展示。

### 2.3 面临的问题

实时日志量非常大，每天处理几十亿条，日志准实时收集，延迟控制在分钟级别，能够支持水平扩展。

### 2.4 业界方案

![image-20241001102652845](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20241001102652845.png)

**ELK方案的问题**

- 运维成本高，每增加一个日志收集项，都需要手动修改配置
- 监控缺失，无法准确获取 logstash 的状态
- 无法做到定制化开发与维护

### 2.5 日志收集系统架构设计

**架构设计**

![image-20241001103105550](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20241001103105550.png)

![image-20241004111317865](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20241004111317865.png)

**组件介绍**

- LogAgent：日志收集客户端，用来收集服务器上的日志
- Kafka：高吞吐量的分布式队列（Linkin 开发，apache 顶级开源项目）
- ElasticSearch：开源的搜索引擎，提供基于 HTTP RESTful 的 web 接口
- Kibana：开源的 ES 数据分析和可视化工具
- Hadoop：分布式计算框架，能够对大量数据进行分布式处理的平台
- Storm：一个免费并开源的分布式实时计算系统

**将学到的技能**

- 服务端 agent 开发
- 后端服务组件开发
- Kafka 和 Zookeeper 的使用
- ES 和 Kibaba 的使用
- etcd 的使用

### 2.6 消息队列的通信模式

**点对点模式（queue）**

消息生产者是生产消息发送到queue中，然后消息消费者从queue中取出并消费消息。一条消息被消费以后，queue中就没有了，不存重复消费。

 **发布/订阅（topic）**

消息生产者（发布）消息发布到 topic 中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到 topic 的消息会被所有订阅者消费。 

## 3. Kafka

### 3.0 实验环境相关命令

```bash
## 启动 zookeeper 命令
[atguigu@hadoop103 zookeeper-3.5.7]$ bin/zkServer.sh start

## 查看 zookeeper 集群节点相关状态
bin/zkServer.sh status

## 启动 kafka 命令
bin/kafka-server-start.sh -daemon config/server.properties

```



### 3.1 介绍

Kafka 是一个分布式数据流平台，可以运行在单台服务上，也可以在多平台服务器上部署形成集群，它提供了发布和订阅功能，使用者可以发送数据到 Kafka 中，也可以从 Kafka 中读取数据（以便进行后续的处理）。Kafka 具有高吞吐，低延迟，高容错等特点。

![image-20241001104821955](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20241001104821955.png)

### 3.2 架构介绍

![image-20241001104920487](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20241001104920487.png)

- Producer：生产者，消息的入口
- Kafka Cluster：kafka 集群，一台或多台服务器组成
  - Broker：部署的服务器的节点，每个 Kafka 集群内的 broker 都有一个不重复的编号
  - Topic：消息的主题，每个 broker 上都可以创建多个 Topic。
  - Partition：分区，分区的作用是负载，提高 Kafka 吞吐量。
  - Replication：副本，每个分区都有多个副本，副本的作用是做备胎。在 Kafka 默认副本的最大数量是 10 个，且副本的数量不能大于 Broker 的数量，follower 和 leader 绝对是在不同的机器，同一个机器对同一个分区也只能存放一个副本（包括自己）
- Consumer：消费者，消息的出口
  - Consumer Group：消费者组将多个消费者组成一个消费者组，在 Kafka 的设计中同一个分区的数据只能被消费者组的某一个消费者消费。同一个消费者组的消费者可以消费同一个 topic 的不同分区的数据，这也是为了提高 kafka 的吞吐量。

### 3.3 工作流程

![image-20241001110428377](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20241001110428377.png)

1. 生产者从 Kafka 集群获取分区 leader 信息
2. 生产者将消息发送给 leader
3. leader 将消息写入本地磁盘
4. follower 从 leader 拉取消息数据
5. follower 将消息写入本地磁盘后向 leader 发送 ACK
6. leader 收到所有的 follower 的 ACK 之后向生产者发送 ACK

### 3.4 选取 partition 的原则

1. partition 在写入的时候可以指定需要写入的 partition ，如果有指定，则写入对应的 partition
2. 如果没有指定 partition ，但是设置了数据的 key ，则会根据 key 的值 hash 出一个 partition
3. 如果既没有指定 partition，又没有设置 key ，则会采用轮询的方式，即每次取一小段时间的数据写入某个 partition ，下一小段的时间写入下一个 partition。

### 3.5 ACK 应答机制

producer 在向 kafka 写入消息的时候，可以设置参数来确定是否确认 Kafka 接收的数据，这个参数可设置的值为 0,1，all

- 0 代表 producer 在往集群发送数据不需要等待集群的返回，不确保消息发送成功。安全性最低但是效率最高
- 1 代表 producer 往集群发送数据只要 leader 应答就可以发送下一条，只确保 leader 发送成功
- all 代表 producer 往集群发送数据需要所有的 follower 都完成从 leader 的同步才会发送下一条，确保 leader 发送成功和所有的副本都完成备份，安全性最高但效率最低。

**注意：如果往不存在的 topic 写数据，kafka 会自定创建 topic , partition 和 replication 的数量默认配置都是 1 ** 

### 3.6 Topic 和 数据日志

topic 是同一类别的消息记录（record）的集合。在 kafka 中，一个主题通常有多个订阅者。对于每个主题，kafka 集群维护了一个分区数据日志文件结构如下：

![image-20241001112629657](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20241001112629657.png)

每个partition都是一个有序并且不可变的消息记录集合。当新的数据写入时，就被追加到partition的末尾。在每个 partition 中，每条消息都会被分配一个顺序的唯一标识，这个标识被称为 offset，即偏移量。注意，kafka 只保证在同一个 partition 内部消息是有序的，在不同 partition之间，并不能保证消息有序。

Kafka 可以配置一个保留期限，用来标识日志会在 kafka 集群内保留多长时间。Kafka集群会保留在期限内所有被发布的消息，不管这些消息是否被消费过。比如保留期限设置为两天，那么数据被发布到 Kafka 集群的两天以内，所以这些数据都可以被消费。当超过两天，这些数据将会被清空，以便为后续的数据腾出空间。由于 Kafka 会将数据进行持久化存储（即写入到硬盘上），所以保留的数据大小可以设置为一个比较大的值。

### 3.7 Partition 结构

Partition 在服务器上的表现形式就是一个一个文件夹，每个 Partition 的文件夹下回有多组 segment 文件，每个 segment 文件又包含 .index 文件，.log 文件, .timeindex 文件三个文件，其中 .log 文件就是实际存储 message 的地方，而 .index 和 .timeindex 文件为索引文件，用于检索消息。

### 3.8 消费数据

![image-20241001113927956](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20241001113927956.png)

### 3.9 使用场景

**消息队列（MQ）**

**追踪网站活动**

**Metrics**

Kafka 经常用来传输监控数据。主要用来聚合分布式应用程序的统计数据，将数据集中后进行统一的分析和展示等。

**日志聚合**

### 3.10 kafka 和 nsq 有什么区别

- nsq：更多的使用来做消息队列
- Kafka：比较重量级的兼顾存储和消息队列

## 4. Zookeeper

ZooKeeper 是一个分布式的，开放源码的分布式应用程序协调服务 ，是 Google 的Chubby 一个开源的实现，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效，功能稳定的系统提供给用户。

## 5.log agent 开发

### 5.1 下载安装 

~~~go
go get github.com/Shopify/sarama
~~~

sarama V1.20 之后的版本加入了 zstd 压缩算法。需要用到 cgo，在 Windows 平台编译时会提示类似如下错误：

~~~shell
# github.com/DataDog/zstd
exec: "gcc": executable file not found in %PATH%
~~~

所以在 Windows 平台请使用 V1.19 版本的 sarama.

**Kafka 生产者**

~~~go
func main() {
	// 生产者配置
	config := sarama.NewConfig()
	config.Producer.RequiredAcks = sarama.WaitForAll          //ACK
	config.Producer.Partitioner = sarama.NewRandomPartitioner //分区
	config.Producer.Return.Successes = true                   //确认

	//连接 Kafka
	client, err := sarama.NewSyncProducer([]string{"172.16.56.129:9092", "172.16.56.130:9092", "172.16.56.134:9092"}, config)
	if err != nil {
		fmt.Println("producer closed, err:", err)
		return
	}
	defer client.Close()

	// 构造消息
	msg := &sarama.ProducerMessage{}
	msg.Topic = "shopping"
	msg.Value = sarama.StringEncoder("2024.10.1 kafka消息发送")

	// 发送消息
	pid, offset, err := client.SendMessage(msg)
	if err != nil {
		fmt.Println("send message failed, err:", err)
		return
	}
	fmt.Printf("pid:%v offset:%v\n", pid, offset)
}
~~~

**Kafka 消费者**

```go
package main

import (
    "fmt"
    "sync"

    "github.com/IBM/sarama"
)

// kafka 消费者
func main() {
    consumer, err := sarama.NewConsumer([]string{"172.16.56.129:9092", "172.16.56.130:9092", "172.16.56.131:9092"}, nil)
    if err != nil {
       fmt.Printf("Failed to start consumer: %s\n", err)
       return
    }

    partitionList, err := consumer.Partitions("web_log")
    if err != nil {
       fmt.Printf("Failed to get list of partitions: %s\n", err)
       return
    }
    fmt.Println(partitionList)
    var wg sync.WaitGroup
    for partition := range partitionList {
       pc, err := consumer.ConsumePartition("web_log", int32(partition), sarama.OffsetNewest)
       if err != nil {
          fmt.Printf("Failed to start consumer for partition %d: %s\n", partition, err)
          return
       }
       defer pc.AsyncClose()
       wg.Add(1)
       go func(partitionConsumer sarama.PartitionConsumer) {
          for msg := range pc.Messages() {
             fmt.Printf("Partition:%d Offset:%d key:%s value:%s\n", msg.Partition, msg.Offset, msg.Key, msg.Value)
          }
       }(pc)
    }
    wg.Wait()
}
```



### 5.2 tailf 包使用

```go
package main

import (
    "fmt"
    "time"

    "github.com/hpcloud/tail"
)

func main() {

    filename := `D:/git/xx.log`
    config := tail.Config{
       ReOpen:    true,
       Follow:    true,
       Location:  &tail.SeekInfo{Offset: 0, Whence: 2},
       MustExist: false,
       Poll:      true,
    }

    // 打开文件开始读取数据
    tails, err := tail.TailFile(filename, config)
    if err != nil {
       fmt.Printf("tail %s failed, err:%v\n", filename, err)
       return
    }

    // 开始读取数据
    var (
       msg *tail.Line
       ok  bool
    )

    for {
       msg, ok = <-tails.Lines // chan
       if !ok {
          fmt.Printf("tail file close reopen, filename:%s\n", tails.Filename)
          time.Sleep(time.Second)
          continue
       }
       fmt.Println("msg:", msg.Text)
    }
}
```

### 5.2 配置文件版 log agent

**ini 配置文件解析**

```go
cfg, err := ini.Load("./conf/config.ini")
if err != nil {
    logrus.Error("load config failed,err:%v", err)
    return
}
kafkaAddr := cfg.Section("kafka").Key("address").String()
fmt.Println(kafkaAddr)
```

### 5.3 etcd

### 5.3.0 etcd 实验环境相关命令

```bash
## 后台启动 etcd 相关命令
nohup etcd --config-file /etc/etcd/etcd.yaml > etcd.log 2>&1 &

## 查看 etcd 节点健康信息
etcdctl --endpoints http://172.16.56.129:2379,172.16.56.130:2379,172.16.56.134:2379 endpoint health --write-out=table

## 查看 etcd 节点状态信息
etcdctl --endpoints http://172.16.56.129:2379,172.16.56.130:2379,172.16.56.134:2379 endpoint status --write-out=table

## 往 etcd 集群中发送数据
etcdctl --endpoints http://172.16.56.129:2379,172.16.56.130:2379,172.16.56.134:2379  put s4 "naszh"
```



类似于 zookeeper，etcd\consul

**介绍**

etcd 是使用 Go 语言开发的一个开源，高可用的分布式 key-value 存储系统，可以用于配置共享和服务的注册和发现。

类是的项目有 zookeeper 和 consul

etcd 具有一下特点：

- 完全复制：集群中的每个节点都可以使用完整的存档
- 高可用性：Etcd 可以用于避免硬件的单点故障或网络问题
- 一致性：每次读取都会返回跨主机的最新写入
- 安全：实现了带有可选的客户端证书身份验证的自动化TLS
- 简单：包括一个定义良好，面向用户的API(gRPC)
- 快速：每秒10000次写入的基准速度
- 可靠：使用Raft算法实现了强一致性，高可用的服务存储目录

**etcd 应用场景**

**服务发现**

服务发现要解决的也是分布式系统中最常见的问题之一，同一个分布式集群中的进程或服务，要如何才能找到对方并建立连接。本质上来说，服务发现就是想要了解集群中是否有进程在监听 udp 或 tcp 端口，并且通过名字就可以查找和连接。

![image-20241001195341884](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20241001195341884.png)

**配置中心**

将一些配置信息放到 etcd 上进行集中管理

这类场景的使用方式通常是这样：应用在启动的时候主动从 etcd 获取一次配置信息，同时，在 etcd 节点上注册一个 Watcher 并等待，以后每次配置有更新的时候，etcd 都会实时通知订阅者，以此达到获取最新配置信息的目的。

**分布式锁**

因为 etcd 使用 Raft 算法保持了数据的强一致性，某次操作存储到集群中的值必然是全局一致的，所以很容易实现分布式锁。锁服务有两种使用方式，一是保持独占，二是控制时序。

- **保持独占即所以获取锁的用户最终只能一个可以得到**。etcd 为此提供了一套实现分布式锁原子操作 CAS（CompareAndSwap）的API。通过设置 prevExist 值，可以保证在多个节点同时去创建某个目录时，只有一个成功，而创建成功的用户就可以认为是获得了锁。
- 控制时序，即所有想要获得锁的用户都会被安排执行，但是获得锁的顺序也是全局唯一的，同时决定了执行顺序。etcd 为此也提供了一套 API（自动创建有序键），对一个目录键值时指定为 POST 动作，这样 etcd 会自动在目录下生成一个当前最大的值为键，存储这个新的值（客户端编号）。同时还可以使用 API 按顺序列出所有当前目录下的键值。此时这些键的值就是客户端的时序，而这些键中存储的值可以是代表客户端的编号。

![image-20241001201156374](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20241001201156374.png)

**etcd 架构**

![image-20241001201557387](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20241001201557387.png)

-  HTTP Server：用来处理用户发送的 API 请求以及其它 etcd 节点的同步心跳信息请求
- Store：用于处理 etcd 支持的各类功能的事务，包括数据索引，节点状态变更，监控与反馈，事件处理与执行等等，是 etcd 对用户提供的大多数 API 功能的具体实现
- Raft：Raft 强一致性算法的具体实现，是 etcd 的核心
- WAL：Write Ahead Log（预写式日志），是 etcd 的数据存储方式。除了在内存中存有所有数据的状态以及节点的索引外，etcd 就通过 WAL 进行持久化存储。WAL 中，所有的数据提交前都会实现记录日志。Snapshot 是为了防止数据过多而进行的状态快照；Entry 表示村粗的具体日志内容。

**etcd 集群**

etcd 作为一个高可用键值对存储系统，天生就是为集群化而设计。由于 Raft 算法在做决策时需要多数节点的投票，所以 etcd 一般部署奇数个节点。

**ectd get 和 put 操作**

```go
package main

import (
    "context"
    "fmt"
    "time"

    "go.etcd.io/etcd/client/v3"
)

// 注意导包 "go.etcd.io/etcd/client/v3" 后续版本应该这样导入

func main() {
    cli, err := clientv3.New(clientv3.Config{
       Endpoints:   []string{"172.16.56.129:2379", "172.16.56.130:2379", "172.16.56.134:2379"},
       DialTimeout: time.Second * 5,
    })
    if err != nil {
       fmt.Printf("connect to etcd failed, err:%v", err)
       return
    }
    defer cli.Close()

    // put
    ctx, cancel := context.WithTimeout(context.Background(), time.Second)
    _, err = cli.Put(ctx, "s4", "真好")
    if err != nil {
       fmt.Printf("put to etcd failed, err:%v", err)
       return
    }
    cancel()

    //get
    ctx, cancel = context.WithTimeout(context.Background(), time.Second)
    gr, err := cli.Get(ctx, "s4")
    if err != nil {
       fmt.Printf("get from etcd failed, err:%v", err)
       return
    }

    for _, ev := range gr.Kvs {
       fmt.Printf("key:%s, value:%s\n", ev.Key, ev.Value)
    }
    cancel()
}
```

**Watch**

监控 etcd 中 key 的变化（创建\更该\删除）

```go
package main

import (
    "context"
    "fmt"
    "time"

    clientv3 "go.etcd.io/etcd/client/v3"
)

// watch
func main() {
    cli, err := clientv3.New(clientv3.Config{
       Endpoints:   []string{"172.16.56.129:2379", "172.16.56.130:2379", "172.16.56.134:2379"},
       DialTimeout: time.Second * 5,
    })
    if err != nil {
       fmt.Printf("connect to etcd failed, err:%v", err)
       return
    }
    defer cli.Close()

    // watch
    watchCh := cli.Watch(context.Background(), "s4")
    for wresp := range watchCh {
       for _, evt := range wresp.Events {
          fmt.Printf("type:%s key:%s value:%s\n", evt.Type, evt.Kv.Key, evt.Kv.Value)
       }
    }
}
```

### 5.4 logagent 使用 etcd 管理收集项

**为每个单独的配置项启动tailTask**

```go
package tailfile

import (
    "strings"
    "time"

    "github.com/IBM/sarama"
    "github.com/guojinghu/logagent/common"
    "github.com/guojinghu/logagent/kafka"
    "github.com/hpcloud/tail"
    "github.com/sirupsen/logrus"
)

// tail 相关操作
type tailTask struct {
    path  string
    topic string
    tObj  *tail.Tail
}

// 根据 topic 和 path 造一个 tailtask 对象
func newTailTask(path, topic string) tailTask {
    tt := tailTask{
       path:  path,
       topic: topic,
    }
    return tt
}


// 使用 tail 包打开日志文件准备读
func (t *tailTask) Init() (err error) {
    cfg := tail.Config{
       ReOpen:    true,                                 // 如果文件被重命名或移动，重新打开文件
       Follow:    true,                                 // 持续跟踪文件的新增内容
       Location:  &tail.SeekInfo{Offset: 0, Whence: 2}, // 从文件末尾开始读取
       MustExist: false,                                // 文件不存在时不报错
       Poll:      true,                                 // 使用轮询方式检查文件变化
    }

    t.tObj, err = tail.TailFile(t.path, cfg)
    return
}

// 实际读日志往 kafka 里发送的方法
func (t *tailTask) run() {
    // 读取日志，发往 Kafka
    logrus.Infof("collect for path:%s is running...", t.path)
    // 循环读数据
    for {
       line, ok := <-t.tObj.Lines // chan
       if !ok {
          logrus.Warn("tailfile file close reopen, filename:%s\n", t.path)
          time.Sleep(time.Second)
          continue
       }

       // 如果是空行就略过
       if len(strings.Trim(line.Text, "\r")) == 0 {
          logrus.Info("出现空行，直接跳过...")
          continue
       }
       // 利用通道将同步的代码改为异步的
       // 把读出来的一行日志包装成kafka的msg类型，丢到通道中
       msg := &sarama.ProducerMessage{}
       msg.Topic = t.topic // 每个 tailObj 自己的topic
       msg.Value = sarama.StringEncoder(line.Text)
       kafka.MsgChan(msg)
    }
}

// 初始化 tailTask 为每一个日志文件造一个单独的 tailTask
func Init(allConf []common.CollectEntry) (err error) {
    // allConf 里面存了存了若干个日志的收集项
    // 针对每一个日志收集项创建一个对应的 tailObj
    for _, conf := range allConf {
       tt := newTailTask(conf.Path, conf.Topic)
       if err = tt.Init(); err != nil {
          logrus.Errorf("create tailObj for path:%s failed, err:%v", conf.Path, err)
          continue
       }
       logrus.Infof("create a tail task for path:%s success...", conf.Path)
       // 起一个后台的goroutine去收集日志
       go tt.run()
    }
    return
}
```

**管理日志收集项**

程序启动之后，拉去了最新的配置之后，就应该派一个小弟去监控 etcd 中，collect_log_conf 这个 key 的变化。

```go
package tailfile

import (
    "github.com/guojinghu/logagent/common"
    "github.com/sirupsen/logrus"
)

// tailTask 的管理者
type tailTaskMgr struct {
    tailTaskMap      map[string]*tailTask       // 所有的tailTask 任务
    collectEntryList []common.CollectEntry      // 所有配置项
    confChan         chan []common.CollectEntry // 等待新配置的通道
}

var (
    ttMgr *tailTaskMgr
)

// main 函数调用
func Init(allConf []common.CollectEntry) (err error) {
    // allConf 里面存了存了若干个日志的收集项
    // 针对每一个日志收集项创建一个对应的 tailObj
    ttMgr = &tailTaskMgr{
       tailTaskMap:      make(map[string]*tailTask, 20),
       collectEntryList: allConf,
       confChan:         make(chan []common.CollectEntry),
    }
    for _, conf := range allConf {
       tt := newTailTask(conf.Path, conf.Topic)
       if err = tt.Init(); err != nil {
          logrus.Errorf("create tailObj for path:%s failed, err:%v", conf.Path, err)
          continue
       }
       logrus.Infof("create a tail task for path:%s success...", conf.Path)
       ttMgr.tailTaskMap[tt.path] = &tt
       // 起一个后台的goroutine去收集日志
       go tt.run()
    }
    go ttMgr.watch() // 在后台等新的配置来

    return
}

// 一直等 confChan 有值，有值就开始去管理之前的tailTask,管理分三种情况1.原来有就什么都不干 2.原来没有现在有就新建 3.原来有现在没有就停止
func (t *tailTaskMgr) watch() {
    for {
       // 派一个小弟等着新配置来
       newConf := <-t.confChan // 取到值说明新的配置来了
       // 新配置来了之后应该管理一下我之前启动的那些新配置
       logrus.Infof("get new conf from etcd, conf:%v, start manager tailTask...", newConf)
       for _, conf := range newConf {
          // 1.原来有存在的任务不需要动
          if t.isExist(conf) {
             continue
          }
          // 2.原来没有的需要新创建一个 tailTask 任务
          tt := newTailTask(conf.Path, conf.Topic)
          if err := tt.Init(); err != nil {
             logrus.Errorf("create tailObj for path:%s failed, err:%v", conf.Path, err)
             continue
          }
          logrus.Infof("create a tail task for path:%s success...", conf.Path)
          ttMgr.tailTaskMap[tt.path] = &tt
          // 起一个后台的goroutine去收集日志
          go tt.run()
       }
       // 3.原来有的现在没有的 tailTask 需要停掉
       // 找出 tailTaskMap 中存在，但是 newConf 不存在的那些 tailTask,把它们都关掉
       for key, task := range t.tailTaskMap {
          var found bool
          for _, conf := range newConf {
             if key == conf.Path {
                found = true
                break
             }
          }
          if !found {
             // 这个 tailTask 要停掉了
             logrus.Infof("the task collect path:%s need to stop.", task.path)
             delete(t.tailTaskMap, key) // 从管理类中删掉
             task.cancel()
          }
       }
    }
}

// 判断 tailTaskMap 中是否存在该收集项
func (t *tailTaskMgr) isExist(conf common.CollectEntry) bool {
    _, ok := t.tailTaskMap[conf.Path]
    return ok
}

// 把新的配置丢到了管理对象的 confChan 中
func SendNewConf(newConf []common.CollectEntry) {
    ttMgr.confChan <- newConf
}
```

**暂留的问题**

如果 logagent 停了需要记录上一次的位置，参考 filebeat

**logagent流程梳理**

https://www.processon.com/mindmap/66fd3dd6d587e65a53e74b2a

### 5.5 logagent

每台服务器上的 logagent 的收集项可能都不一致，我们需要让 logagent 去etcd 中根据 ip 获取自己的配置

![image-20241002211658944](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20241002211658944.png)

**如何获取本机的IP**

```go
// 获取本机IP
func GetOutBoundIP() (ip string, err error) {
    conn, err := net.Dial("udp", "8.8.8.8:80")
    if err != nil {
       return
    }
    defer conn.Close()

    ip = conn.LocalAddr().(*net.UDPAddr).IP.String()
    //fmt.Println(localAddr.String())
    return
}
```

**logagent 中集成根据 ip 拉取配置**

![image-20241002214146429](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20241002214146429.png)

**etcd 中配置的 key 要注意使用 IP**

![image-20241002214247057](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20241002214247057.png)

### 5.6 gopsutil 包

psutil 是一个跨平台进程和系统监控的Python库，而 gopsutil 是其 Go 语言版本实现。

Go 语言部署简单，性能好的特点非常适合做一些诸如采集系统信息和系统监控的服务。

```bash
## 安装
go get github.com/shirou/gopsutil
```

**获取 CPU 信息**

```go
// 获取cpu信息
func getCpuInfo() {
    cpuInfos, err := cpu.Info()
    if err != nil {
       fmt.Printf("get cpu info failed, err:%v\n", err)
    }

    //获取cpu信息
    for _, ci := range cpuInfos {
       fmt.Println(ci)
    }

    for {
       // 获取Cpu使用率
       percent, _ := cpu.Percent(time.Second, false)
       fmt.Printf("cpu precent:%v\n", percent)
    }
}

// cpu 负载 在windows下可能会出现问题
func getLoad() {
	info, err := load.Avg()
	if err != nil {
		fmt.Printf("get load failed, err:%v\n", err)
		return
	}
	fmt.Println(info)
}
```

**内存**

```go
// 内存信息
func getMemInfo() {
    info, err := mem.VirtualMemory()
    if err != nil {
       fmt.Printf("get mem info failed, err:%v\n", err)
       return
    }

    fmt.Println(info)
}
```

**主机信息**

```go
// 主机信息
func getHostInfo() {
    hInfo, _ := host.Info()
    fmt.Printf("host info:%v uptime:%v boottime:%v\n", hInfo, hInfo.Uptime, hInfo.BootTime)
}
```

**磁盘**

```go
// Disk 磁盘信息
func getDiskInfo() {
    // 获取所有分区信息
    parts, err := disk.Partitions(true)
    if err != nil {
       fmt.Printf("get disk info failed, err:%v\n", err)
       return
    }
    fmt.Println(parts)
    for _, part := range parts {
       partInfo, err := disk.Usage(part.Mountpoint)
       if err != nil {
          fmt.Printf("get disk info failed, err:%v\n", err)
          return
       }
       fmt.Println(partInfo)
    }
    // 磁盘IO
    ioStat, _ := disk.IOCounters()
    for k, v := range ioStat {
       fmt.Printf("%v:%v\n", k, v)
    }
}
```

**net 网络**

```go
// net 相关
func getNetInfo() {
    netIOs, err := net.IOCounters(true)
    if err != nil {
       fmt.Printf("get net info failed, err:%v\n", err)
       return
    }

    for _, v := range netIOs {
       fmt.Printf("%v:%v:%v\n", v.Name, v.BytesRecv, v.BytesSent)
    }
}
```



### 5.6 **influxDB 时序数据库**

InfluxDB 是一个开源分布式时序，事件和指标数据库。使用 Go 语言编写，无需外部依赖，其设计目标是实现分布式和水平伸缩扩展。

https://www.influxdata.com/index/

**influxDB 介绍**

**名词介绍**

| influxDB 名词 | 传统数据库概念 |
| ------------- | -------------- |
| database      | 数据库         |
| measurement   | 数据表         |
| point         | 数据行         |

**point**

influxDB 中的point相当于传统数据库中的一行数据，由时间戳（time），数据（field），标签（tag）组成

| Point属性 | 传统数据库概念                               |
| --------- | -------------------------------------------- |
| time      | 每个数据记录时间，是数据库中的主索引         |
| field     | 各种记录值（没有索引的属性），例如温度，湿度 |
| tags      | 各种有索引的属性，例如地区，海拔             |

**Series**

Series 相当于是 InfluxDB 中一些数据的集合，在同一个 database 中，完全相同的数据同属于一个 series，同一个 series 的数据在物理上会按照时间顺序排列存储在一起。

**Go 操作 influxDB**

```go
// influxDB 1.x 版本
go get github.com/influxdata/influxdb1-client/v2
	
// influxDB 2.x 版本
go get github.com/influxdata/influxdb-client-go
```

### 5.6.**grafana** + influxDB + gopsutil 实现本地机器指标检测

代码：https://github.com/guojingh/golang_demo/tree/master/third/collect_info

![image-20241004110600970](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20241004110600970.png)

![image-20241004105247505](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20241004105247505.png)

### 5.7 Elastic search

开源的搜索引擎，java开发，Elasticsearch 基于 Lucene 构建，提供了强大的全文搜索功能，并且具有广泛的应用领域，包括日志和实时分析、社交媒体、电子商务等。

**Elasticsearch 能做什么**

- 为APP或网站增加搜索功能
- 存储和分析日志、指标和安全事件数据
- 使用机器学习实时自动建模数据的行为
- 使用Elasticsearch作为存储引擎自动化业务工作流
- 使用Elasticsearch作为地理信息系统（GIS）管理、集成和分析空间信息
- 使用Elasticsearch作为生物信息学研究工具存储和处理遗传数据

**倒排索引（reversed Index）**

****

****

**Elastic search 基本概念**

- Near Realtime（NRT）几乎实时
- Cluster 集群
- Node 节点
- Index 索引：具有相似特性的文档集合
- Type 类型：类型是索引的逻辑类别/分区
- Document 文档：文档是可以被索引信息的基本单位，表示形式为 JSON
- Shards & Replicas 分区与副本

**ES 基本概念与关系型数据库的比较**

| ES 概念                                        | 关系型数据库        |
| ---------------------------------------------- | ------------------- |
| Index（索引）支持全文检索                      | Database （数据库） |
| Type（类型）                                   | Table（表）         |
| Document（文档），不同文档可以有不同的字段集合 | Row（数据行）       |
| Field（字段）                                  | Column（数据列）    |
| Mapping（映射）                                | Schema（模式）      |

**ES 集群安装**

文档：https://juejin.cn/post/7267477916743811108

ES 对应版本信息

```json
{
  "name" : "k8s-01",
  "cluster_name" : "elk-logs",
  "cluster_uuid" : "XlkSwtIIREKOBU4_Sl8tYw",
  "version" : {
    "number" : "8.15.2",
    "build_flavor" : "default",
    "build_type" : "deb",
    "build_hash" : "98adf7bf6bb69b66ab95b761c9e5aadb0bb059a3",
    "build_date" : "2024-09-19T10:06:03.564235954Z",
    "build_snapshot" : false,
    "lucene_version" : "9.11.1",
    "minimum_wire_compatibility_version" : "7.17.0",
    "minimum_index_compatibility_version" : "7.0.0"
  },
  "tagline" : "You Know, for Search"
}

```



**ES 相关命令**

```bash
## 查询节点状态
curl -k -u elastic:56cbAsZvVChJgBiid3E3 "https://127.0.0.1:9200/_cluster/health?pretty"

## 添加 index
curl -k -u elastic:56cbAsZvVChJgBiid3E3 -X PUT "https://127.0.0.1:9200/user" -H 'Content-Type: application/json' -d'
{
  "settings": {
    "index": {
      "number_of_shards": 1,
      "number_of_replicas": 1
    }
  },
  "mappings": {
    "properties": {
      "name": { "type": "text" },
      "age": { "type": "integer" },
	  "married": {"type": "boolean"}
    }
  }
}
'

## 添加 doc
curl -k -u elastic:56cbAsZvVChJgBiid3E3 -X POST "https://127.0.0.1:9200/user/_doc/" -H 'Content-Type: application/json' -d'
{
  "name": "John Doe",
  "age": 30,
  "married": true
}
'

## 批量添加
curl -k -u elastic:56cbAsZvVChJgBiid3E3 -X POST "https://127.0.0.1:9200/user/_bulk" -H 'Content-Type: application/json' -d'
{ "index": { } }
{ "name": "Alice", "age": 25, "married": true }
{ "index": { } }
{ "name": "Bob", "age": 28, "married": false }

## 查询 doc
curl -k -u elastic:56cbAsZvVChJgBiid3E3 -X GET "https://127.0.0.1:9200/user/_search" -H 'Content-Type: application/json' -d'
{
  "query": {
    "match": {
      "name": "John Doe"
    }
  }
}
'

```

**完整项目架构图**

![image-20241004205846195](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20241004205846195.png)

项目代码：

logagent:https://github.com/guojingh/golang_demo/tree/master/logagent

log_transfer:https://github.com/guojingh/golang_demo/tree/master/log_transfer













































